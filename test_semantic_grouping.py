import streamlit as st
import json
import os
from typing import List, Dict, Tuple
import asyncio
from openai import AsyncOpenAI
from anthropic import AsyncAnthropic

# ============================ KONFIGURACJA ============================

st.set_page_config(
    page_title="üß† Semantic Grouping Tester",
    page_icon="üß†",
    layout="wide"
)

# ============================ AI CLIENTS ============================

@st.cache_resource
def get_openai_client():
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        st.error("‚ùå OPENAI_API_KEY nie jest ustawiony!")
        return None
    return AsyncOpenAI(api_key=api_key)

@st.cache_resource  
def get_claude_client():
    api_key = os.getenv("ANTHROPIC_API_KEY")
    if not api_key:
        st.error("‚ùå ANTHROPIC_API_KEY nie jest ustawiony!")
        return None
    return AsyncAnthropic(api_key=api_key)

# ============================ AI FUNCTIONS ============================

async def call_openai_grouping(client, system_prompt: str, user_prompt: str, model: str = "gpt-4o") -> Dict:
    """Wywo≈Çaj OpenAI API do grupowania"""
    try:
        response = await client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.0,
            response_format={"type": "json_object"}
        )
        
        result = json.loads(response.choices[0].message.content)
        return {
            "success": True,
            "result": result,
            "tokens": response.usage.total_tokens,
            "cost": response.usage.total_tokens * 0.000015  # Przybli≈ºony koszt
        }
    except Exception as e:
        return {"success": False, "error": str(e)}

async def call_claude_grouping(client, system_prompt: str, user_prompt: str, model: str = "claude-3-5-sonnet-20241022") -> Dict:
    """Wywo≈Çaj Claude API do grupowania"""
    try:
        response = await client.messages.create(
            model=model,
            max_tokens=4000,
            temperature=0.0,
            system=system_prompt,
            messages=[{"role": "user", "content": user_prompt}]
        )
        
        # Claude mo≈ºe zwr√≥ciƒá JSON w tek≈õcie
        content = response.content[0].text
        if "```json" in content:
            json_start = content.find("```json") + 7
            json_end = content.find("```", json_start)
            content = content[json_start:json_end].strip()
        
        result = json.loads(content)
        return {
            "success": True,
            "result": result,
            "tokens": response.usage.input_tokens + response.usage.output_tokens,
            "cost": (response.usage.input_tokens * 0.000003) + (response.usage.output_tokens * 0.000015)
        }
    except Exception as e:
        return {"success": False, "error": str(e)}

# ============================ PROMPTY DOMY≈öLNE ============================

DEFAULT_SYSTEM_PROMPT = """Jeste≈õ ekspertem grupowania fraz semantycznie. Grupujesz frazy tak, jak zrobi≈Çby to cz≈Çowiek my≈õlƒÖcy o stronach internetowych."""

DEFAULT_USER_PROMPT_TEMPLATE = """Pogrupuj te frazy na temat "{seed_keyword}" w sensowne grupy semantyczne.

ZASADY UNIWERSALNE:
1. Ka≈ºda grupa = jedna strona internetowa  
2. PREFERUJ WIƒòKSZE GRUPY - ≈ÇƒÖcz co siƒô da semantycznie
3. Outliers = TYLKO frazy kompletnie spoza tematu (maksymalnie 10%)
4. Docelowo 4-8 du≈ºych grup po 10-25 fraz ka≈ºda
5. Lepiej jedna du≈ºa grupa ni≈º 3 ma≈Çe mikrogrupy

FRAZY:
{formatted_phrases}

WA≈ªNE: ≈ÅƒÖcz frazy o podobnej intencji w du≈ºe, u≈ºyteczne grupy!

JSON:
{{
  "groups": [
    {{
      "name": "Nazwa grupy",
      "phrases": ["fraza1", "fraza2", "fraza3"]
    }}
  ],
  "outliers": ["tylko_je≈õli_kompletnie_spoza_tematu"]
}}"""

# ============================ STREAMLIT UI ============================

st.title("üß† Semantic Grouping Tester")
st.markdown("**Testuj r√≥≈ºne prompty dla grupowania semantycznego fraz**")

# ============================ SIDEBAR - KONFIGURACJA ============================

st.sidebar.header("‚öôÔ∏è Konfiguracja")

# Wyb√≥r AI Provider
ai_provider = st.sidebar.selectbox(
    "ü§ñ AI Provider",
    ["OpenAI", "Claude"],
    index=0
)

# Model selection
if ai_provider == "OpenAI":
    model = st.sidebar.selectbox(
        "üì± Model OpenAI", 
        ["gpt-4o", "gpt-4", "gpt-3.5-turbo"],
        index=0
    )
else:
    model = st.sidebar.selectbox(
        "üì± Model Claude",
        ["claude-3-5-sonnet-20241022", "claude-3-sonnet-20240229"],
        index=0
    )

# ============================ MAIN INTERFACE ============================

# Kolumny
col1, col2 = st.columns([1, 1])

with col1:
    st.header("üìù Input")
    
    # Seed keyword
    seed_keyword = st.text_input(
        "üéØ G≈Ç√≥wne s≈Çowo kluczowe (temat)",
        value="soczewki kontaktowe",
        help="G≈Ç√≥wny temat wok√≥≈Ç kt√≥rego bƒôdƒÖ grupowane frazy"
    )
    
    # Lista fraz
    st.subheader("üìã Lista fraz (jedna na liniƒô)")
    phrases_text = st.text_area(
        "Frazy do pogrupowania:",
        value="""biofinity soczewki
soczewki progresywne
soczewki astygmatyzm
soczewki toryczne
soczewki kontaktowe miesiƒôczne
family optic twoje soczewki
soczewki biofinity
kolorowe soczewki kontaktowe
soczewki kontaktowe cena
acuvue oasys soczewki
soczewki acuvue oasys
soczewki acuvue
acuvue soczewki
acuvue oasys
ACUVUE OASYS 1-Day
Acuvue Oasys for ASTIGMATISM""",
        height=200
    )
    
    # Konwersja na listƒô
    phrases_list = [line.strip() for line in phrases_text.split('\n') if line.strip()]
    st.info(f"üìä Znaleziono **{len(phrases_list)}** fraz do grupowania")

with col2:
    st.header("üéõÔ∏è Prompty")
    
    # System prompt
    st.subheader("ü§ñ System Prompt")
    system_prompt = st.text_area(
        "System prompt:",
        value=DEFAULT_SYSTEM_PROMPT,
        height=100,
        help="Instrukcje dla AI o roli i kontek≈õcie"
    )
    
    # User prompt template
    st.subheader("üë§ User Prompt Template")
    user_prompt_template = st.text_area(
        "User prompt (u≈ºyj {seed_keyword} i {formatted_phrases}):",
        value=DEFAULT_USER_PROMPT_TEMPLATE,
        height=300,
        help="G≈Ç√≥wne instrukcje dla AI. U≈ºyj {seed_keyword} i {formatted_phrases} jako placeholdery"
    )

# ============================ BUTTON & EXECUTION ============================

st.markdown("---")

if st.button("üöÄ **GRUPUJ FRAZY**", type="primary", use_container_width=True):
    if not phrases_list:
        st.error("‚ùå Podaj przynajmniej jednƒÖ frazƒô!")
    elif not seed_keyword:
        st.error("‚ùå Podaj g≈Ç√≥wne s≈Çowo kluczowe!")
    else:
        # Przygotuj prompt
        formatted_phrases = "\n".join(f"- {phrase}" for phrase in phrases_list)
        user_prompt = user_prompt_template.format(
            seed_keyword=seed_keyword,
            formatted_phrases=formatted_phrases
        )
        
        # Progress bar
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        # Call AI
        async def run_grouping():
            status_text.text("ü§ñ ≈ÅƒÖczenie z AI...")
            progress_bar.progress(25)
            
            if ai_provider == "OpenAI":
                client = get_openai_client()
                if not client:
                    return None
                status_text.text("ü§ñ Wywo≈Çywanie OpenAI...")
                progress_bar.progress(50)
                result = await call_openai_grouping(client, system_prompt, user_prompt, model)
            else:
                client = get_claude_client()
                if not client:
                    return None
                status_text.text("ü§ñ Wywo≈Çywanie Claude...")
                progress_bar.progress(50)
                result = await call_claude_grouping(client, system_prompt, user_prompt, model)
                
            progress_bar.progress(100)
            status_text.text("‚úÖ Gotowe!")
            return result
        
        # Execute
        try:
            result = asyncio.run(run_grouping())
            
            # Clear progress
            progress_bar.empty()
            status_text.empty()
            
            if result and result.get("success"):
                st.success("‚úÖ **Grupowanie zako≈Ñczone sukcesem!**")
                
                # Wyniki w kolumnach
                res_col1, res_col2 = st.columns([2, 1])
                
                with res_col1:
                    st.header("üìä Wyniki grupowania")
                    
                    groups = result["result"].get("groups", [])
                    outliers = result["result"].get("outliers", [])
                    
                    # Statystyki
                    total_phrases_in_groups = sum(len(group["phrases"]) for group in groups)
                    outlier_percentage = (len(outliers) / len(phrases_list)) * 100 if phrases_list else 0
                    
                    st.metric("üéØ Liczba grup", len(groups))
                    st.metric("üìà Frazy w grupach", f"{total_phrases_in_groups}/{len(phrases_list)}")
                    st.metric("‚ö†Ô∏è Outliers", f"{len(outliers)} ({outlier_percentage:.1f}%)")
                    
                    # Poka≈º grupy
                    for i, group in enumerate(groups, 1):
                        with st.expander(f"**Grupa {i}: {group['name']}** ({len(group['phrases'])} fraz)", expanded=True):
                            for phrase in group['phrases']:
                                st.write(f"‚Ä¢ {phrase}")
                    
                    # Outliers
                    if outliers:
                        with st.expander(f"‚ö†Ô∏è **Outliers** ({len(outliers)} fraz)", expanded=True):
                            for phrase in outliers:
                                st.write(f"‚Ä¢ {phrase}")
                
                with res_col2:
                    st.header("üìà Statystyki")
                    st.metric("üéØ Tokeny", result.get("tokens", 0))
                    st.metric("üí∞ Koszt", f"${result.get('cost', 0):.6f}")
                    st.metric("ü§ñ Provider", ai_provider)
                    st.metric("üì± Model", model)
                    
                    # Raw JSON
                    st.subheader("üîß Raw JSON Response")
                    st.json(result["result"])
                    
            else:
                st.error(f"‚ùå **B≈ÇƒÖd podczas grupowania:**\n{result.get('error', 'Nieznany b≈ÇƒÖd')}")
                
        except Exception as e:
            progress_bar.empty()
            status_text.empty()
            st.error(f"‚ùå **B≈ÇƒÖd wykonania:** {str(e)}")

# ============================ FOOTER ============================

st.markdown("---")
st.markdown("**üí° Tip:** Eksperymentuj z r√≥≈ºnymi promptami ≈ºeby znale≈∫ƒá optymalne grupowanie!") 